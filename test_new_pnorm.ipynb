{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from itertools import product\n",
    "from math import inf, pi\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.experimental.ode import odeint\n",
    "import jax.debug as jdb\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from dynamics import prior, disturbance, plant\n",
    "from utils import params_to_posdef\n",
    "from utils import random_ragged_spline, spline\n",
    "from utils import (tree_normsq, rk38_step, epoch,   # noqa: E402\n",
    "                   odeint_fixed_step, odeint_ckpt, random_ragged_spline, spline,\n",
    "            params_to_cholesky, params_to_posdef)\n",
    "\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "plt.rcParams.update({'font.size': 24})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_p_qbar(p):\n",
    "    return np.sqrt(1/(1 - 1/p) - 1.1)\n",
    "\n",
    "def convert_qbar_p(qbar):\n",
    "    return 1/(1 - 1/(1.1 + qbar**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support functions for generating loop reference trajectory\n",
    "def reference(t):\n",
    "    T = 10.            # loop period\n",
    "    d = 4.             # displacement along `x` from `t=0` to `t=T`\n",
    "    w = 4.             # loop width\n",
    "    h = 6.             # loop height\n",
    "    ϕ_max = jnp.pi/3   # maximum roll angle (achieved at top of loop)\n",
    "\n",
    "    x = (w/2)*jnp.sin(2*jnp.pi * t/T) + d*(t/T)\n",
    "    y = (h/2)*(1 - jnp.cos(2*jnp.pi * t/T))\n",
    "    ϕ = 4*ϕ_max*(t/T)*(1-t/T)\n",
    "    r = jnp.array([x, y, ϕ])\n",
    "    return r\n",
    "\n",
    "def odeint_fixed_step(func, x0, t0, t1, step_size, *args):\n",
    "    \"\"\"TODO: docstring.\"\"\"\n",
    "    # Use `numpy` for purely static operations on static arguments\n",
    "    # (see: https://github.com/google/jax/issues/5208)\n",
    "    # jdebug.print('{t1_type}', t1_type=type(t1))\n",
    "    num_steps = 10\n",
    "\n",
    "    ts = jnp.linspace(t0, t1, num_steps + 1)\n",
    "    xs = odeint_ckpt(func, x0, ts, *args)\n",
    "    return xs, ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_simulate(ts, w, params, reference,\n",
    "                plant=plant, prior=prior, disturbance=disturbance, NGD_flag=False):\n",
    "    \"\"\"TODO: docstring.\"\"\"\n",
    "    # Required derivatives of the reference trajectory\n",
    "    def ref_derivatives(t):\n",
    "        ref_vel = jax.jacfwd(reference)\n",
    "        ref_acc = jax.jacfwd(ref_vel)\n",
    "        r = reference(t)\n",
    "        dr = ref_vel(t)\n",
    "        ddr = ref_acc(t)\n",
    "        return r, dr, ddr\n",
    "\n",
    "    # Adaptation law\n",
    "    def adaptation_law(q, dq, r, dr, params=params, NGD_flag=NGD_flag):\n",
    "        # Regressor features\n",
    "        y = jnp.concatenate((q, dq))\n",
    "        for W, b in zip(params['W'], params['b']):\n",
    "            y = jnp.tanh(W@y + b)\n",
    "\n",
    "        # Auxiliary signals\n",
    "        Λ, P = params['Λ'], params['P']\n",
    "        e, de = q - r, dq - dr\n",
    "        s = de + Λ@e\n",
    "\n",
    "        \n",
    "        dA = P @ jnp.outer(s, y)\n",
    "        return dA, y\n",
    "\n",
    "    # Controller\n",
    "    def controller(q, dq, r, dr, ddr, f_hat, params=params):\n",
    "        # Auxiliary signals\n",
    "        Λ, K = params['Λ'], params['K']\n",
    "        e, de = q - r, dq - dr\n",
    "        s = de + Λ@e\n",
    "        v, dv = dr - Λ@e, ddr - Λ@de\n",
    "\n",
    "        # Control input and adaptation law\n",
    "        H, C, g, B = prior(q, dq)\n",
    "        τ = H@dv + C@v + g - f_hat - K@s\n",
    "        u = jnp.linalg.solve(B, τ)\n",
    "        return u, τ\n",
    "\n",
    "    # Closed-loop ODE for `x = (q, dq)`, with a zero-order hold on\n",
    "    # the controller\n",
    "    def ode(x, t, u, w=w):\n",
    "        q, dq = x\n",
    "        f_ext = disturbance(q, dq, w)\n",
    "        ddq = plant(q, dq, u, f_ext)\n",
    "        dx = (dq, ddq)\n",
    "        return dx\n",
    "\n",
    "    # Simulation loop\n",
    "    def loop(carry, input_slice, params=params):\n",
    "        t_prev, q_prev, dq_prev, u_prev, A_prev, dA_prev, pA_prev = carry\n",
    "        t = input_slice\n",
    "        zs, ts = odeint_fixed_step(ode, (q_prev, dq_prev), t_prev, t, 2e-3,\n",
    "                            u_prev)\n",
    "        qs, dqs = zs\n",
    "        q = qs[-1]\n",
    "        dq = dqs[-1]\n",
    "\n",
    "        r, dr, ddr = ref_derivatives(t)\n",
    "\n",
    "        if NGD_flag:\n",
    "            qn = 1.1 + params['pnorm']**2\n",
    "\n",
    "            # Integrate adaptation law via trapezoidal rule\n",
    "            dA, y = adaptation_law(q, dq, r, dr)\n",
    "            pA = pA_prev + (t - t_prev)*(dA_prev + dA)/2\n",
    "            # A = (jnp.maximum(jnp.abs(pA), 1e-6 * jnp.ones_like(pA))**(qn-1) * jnp.sign(pA)* (jnp.ones_like(pA) - jnp.isclose(pA, 0, atol=1e-6)) ) @ params['P']\n",
    "            # A = jnp.abs(pA)**(qn-1) * jnp.sign(pA) @ params['P']\n",
    "            A = params['P'] @ jnp.abs(pA)**(qn-1) * jnp.sign(pA)\n",
    "        else:\n",
    "            # Integrate adaptation law via trapezoidal rule\n",
    "            dA, y = adaptation_law(q, dq, r, dr)\n",
    "            A = A_prev + (t - t_prev)*(dA_prev + dA)/2\n",
    "            pA = pA0\n",
    "\n",
    "        # Compute force estimate and control input\n",
    "        f_hat = A @ y\n",
    "        u, τ = controller(q, dq, r, dr, ddr, f_hat)\n",
    "\n",
    "        f_ext = disturbance(q, dq, w)\n",
    "\n",
    "        carry = (t, q, dq, u, A, dA, pA)\n",
    "        flat_A = A.flatten()\n",
    "        output_slice = (q, dq, u, τ, r, dr, f_hat, f_ext, y, flat_A)\n",
    "        return carry, output_slice\n",
    "\n",
    "    # Initial conditions\n",
    "    t0 = ts[0]\n",
    "    r0, dr0, ddr0 = ref_derivatives(t0)\n",
    "    q0, dq0 = r0, dr0\n",
    "    dA0, y0 = adaptation_law(q0, dq0, r0, dr0)\n",
    "    A0 = jnp.zeros((q0.size, y0.size))\n",
    "    pA0 = jnp.ones((q0.size, y0.size))\n",
    "    f0 = A0 @ y0\n",
    "    u0, τ0 = controller(q0, dq0, r0, dr0, ddr0, f0)\n",
    "    f_ext0 = disturbance(q0, dq0, w)\n",
    "\n",
    "    flat_A0 = A0.flatten()\n",
    "\n",
    "    # Run simulation loop\n",
    "    carry = (t0, q0, dq0, u0, A0, dA0, pA0)\n",
    "    carry, output = jax.lax.scan(loop, carry, ts[1:])\n",
    "    q, dq, u, τ, r, dr, f_hat, f_ext, y, flat_A = output\n",
    "\n",
    "    # Prepend initial conditions\n",
    "    q = jnp.vstack((q0, q))\n",
    "    dq = jnp.vstack((dq0, dq))\n",
    "    u = jnp.vstack((u0, u))\n",
    "    τ = jnp.vstack((τ0, τ))\n",
    "    r = jnp.vstack((r0, r))\n",
    "    dr = jnp.vstack((dr0, dr))\n",
    "    f_hat = jnp.vstack((f0, f_hat))\n",
    "    f_ext = jnp.vstack((f_ext0, f_ext))\n",
    "    flat_A = jnp.vstack((flat_A0, flat_A))\n",
    "    y = jnp.vstack((y0, y))\n",
    "\n",
    "    sim = {\"q\": q, \"dq\": dq, \"u\": u, \"τ\": τ, \"r\": r, \"dr\": dr, \"f_hat\": f_hat, \"f_ext\": f_ext, \"y\": y, \"A\": flat_A}\n",
    "\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_single_model(model_dir, filename, T, dt, w, pnorm_flag=True, visual_verbose=0, save_dir=None, fixed_P=None):\n",
    "    model_pkl_loc = os.path.join(model_dir, filename)\n",
    "    with open(model_pkl_loc, 'rb') as f:\n",
    "        train_results = pickle.load(f)\n",
    "\n",
    "    test_results = {}\n",
    "    test_params = {}  \n",
    "\n",
    "    parts = filename.replace('.pkl', '').split('_')\n",
    "        \n",
    "    # Dictionary to hold the attributes for this file\n",
    "    test_results['train_params'] = {}\n",
    "    # Loop through each part of the filename\n",
    "    for part in parts:\n",
    "        # Split each part by '=' to separate the key and value\n",
    "        key, value = part.split('=')\n",
    "        # Convert value to float if it looks like a number, else keep as string\n",
    "        try:\n",
    "            test_results['train_params'][key] = float(value)\n",
    "        except ValueError:\n",
    "            test_results['train_params'][key] = value\n",
    "\n",
    "    # Post-process training loss information\n",
    "    # train_aux = train_results['train_lossaux_history']\n",
    "    # train_loss_history = jnp.zeros(train_results['train_params']['E'])\n",
    "    # for i in range(test_results['train_params']['E']):\n",
    "    #     train_loss_history[i] = train_aux[i]['tracking_loss'] + 1e-3 * train_aux[i]['control_loss'] + 1e-4 * train_aux[i]['l2_penalty'] + test_results['train_params']['regP'] * train_aux[i]['reg_P_penalty']\n",
    "\n",
    "    test_results['train_info'] = {\n",
    "        'best_step_meta': train_results['best_step_meta'],\n",
    "        'ensemble': train_results['ensemble'],\n",
    "        'valid_loss_history': train_results['valid_loss_history'],\n",
    "        # 'train_loss_history': train_results['train_loss_history'],\n",
    "        'pnorm_history': train_results['pnorm_history']\n",
    "    }\n",
    "    # test_results['train_info']['pnorm_history'].prepend(test_results['train_params']['pinit'])\n",
    "\n",
    "    if pnorm_flag:\n",
    "        test_results['final_p'] = train_results['pnorm']\n",
    "        # Note that the pnorm stored in pickle is the actual p\n",
    "        # To run evaluation script, we convert params['pnorm'] to qbar\n",
    "        test_params['pnorm'] = convert_p_qbar(train_results['pnorm'])\n",
    "    else:\n",
    "        test_results['final_p'] = 2.0\n",
    "    \n",
    "\n",
    "    # Store the model parameters\n",
    "    test_params['W'] = train_results['model']['W']\n",
    "    test_params['b'] = train_results['model']['b']\n",
    "    test_params['Λ'] = params_to_posdef(train_results['controller']['Λ'])\n",
    "    test_params['K'] = params_to_posdef(train_results['controller']['K'])\n",
    "    if fixed_P == None:\n",
    "        test_params['P'] = params_to_posdef(train_results['controller']['P'])\n",
    "    else:\n",
    "        P_size = params_to_posdef(train_results['controller']['P']).shape[0]\n",
    "        test_params['P'] = jnp.eye(P_size) * fixed_P\n",
    "\n",
    "    # Test on new trajectories\n",
    "    ts = jnp.arange(0, T, dt)\n",
    "    sim = test_simulate(ts, w, test_params, reference, NGD_flag=pnorm_flag)\n",
    "\n",
    "    sim_e = sim['q'] - sim['r']\n",
    "    tracking_error = jnp.mean(jnp.linalg.norm(sim_e, axis=1))\n",
    "    sim_ftilde = sim['f_hat'] - sim['f_ext']\n",
    "    estimation_error = jnp.mean(jnp.linalg.norm(sim_ftilde, axis=1))\n",
    "\n",
    "    test_results['tracking_err'] = tracking_error\n",
    "    test_results['estimation_err'] = estimation_error\n",
    "\n",
    "    if os.path.exists(os.path.join(model_dir, 'figs')) == False:\n",
    "        os.makedirs(os.path.join(model_dir, 'figs'))\n",
    "        \n",
    "    if visual_verbose > 0:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "        if test_results['train_params']['pfreq'] > test_results['train_params']['E']:\n",
    "            ax[0].axhline(test_results['final_p'], 0, test_results['train_params']['E'], label='final p')\n",
    "        else:\n",
    "            ax[0].step(np.arange(0, test_results['train_params']['E'], test_results['train_params']['pfreq']), test_results['train_info']['pnorm_history'])\n",
    "        ax[0].set_ylabel('p')\n",
    "        ax[0].set_xlabel('Epochs')\n",
    "        ax[0].set_title('p_init = {}'.format(test_results['train_params']['pinit']))\n",
    "\n",
    "        ax[1].plot(range(int(test_results['train_params']['E'])), test_results['train_info']['valid_loss_history'])\n",
    "        ax[1].set_title('Validation Loss')\n",
    "        ax[1].set_ylabel('Val Loss')\n",
    "        ax[1].set_xlabel('Epochs')\n",
    "\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(os.path.join(model_dir, 'figs/train_info_{}'.format(filename.replace('.pkl', '.png'))))\n",
    "        plt.close(fig)\n",
    "\n",
    "        if visual_verbose > 1:\n",
    "            fig, ax = plt.subplots(1, 3, figsize=(30, 10))\n",
    "            ax[0].plot(ts, sim['q'][:, 0], label='q')\n",
    "            ax[0].plot(ts, sim['r'][:, 0], label='r')\n",
    "            ax[0].set_ylabel('x')\n",
    "            ax[0].set_xlabel('t')\n",
    "            ax[0].legend()\n",
    "\n",
    "            ax[1].plot(ts, sim['q'][:, 1], label='q')\n",
    "            ax[1].plot(ts, sim['r'][:, 1], label='r')\n",
    "            ax[1].set_ylabel('y')\n",
    "            ax[1].set_xlabel('t')\n",
    "            ax[1].legend()\n",
    "\n",
    "            ax[2].plot(ts, sim['q'][:, 2], label='q')\n",
    "            ax[2].plot(ts, sim['r'][:, 2], label='r')\n",
    "            ax[2].set_ylabel('ϕ')\n",
    "            ax[2].set_xlabel('t')\n",
    "            ax[2].legend()\n",
    "\n",
    "            fig.tight_layout()\n",
    "            fig.savefig(os.path.join(model_dir, 'figs/tracking_{}'.format(filename.replace('.pkl', '.png'))))\n",
    "            plt.close(fig)\n",
    "            if visual_verbose > 2:\n",
    "                fig, ax = plt.subplots(1, 3, figsize=(30, 10))\n",
    "                ax[0].plot(ts, sim['f_hat'][:, 0], label='f_hat')\n",
    "                ax[0].plot(ts, sim['f_ext'][:, 0], label='f_ext')\n",
    "                ax[0].set_ylabel('f_x')\n",
    "                ax[0].set_xlabel('t')\n",
    "                ax[0].legend()\n",
    "\n",
    "                ax[1].plot(ts, sim['f_hat'][:, 1], label='f_hat')\n",
    "                ax[1].plot(ts, sim['f_ext'][:, 1], label='f_ext')\n",
    "                ax[1].set_ylabel('f_y')\n",
    "                ax[1].set_xlabel('t')\n",
    "                ax[1].legend()\n",
    "\n",
    "                ax[2].plot(ts, sim['f_hat'][:, 2], label='f_hat')\n",
    "                ax[2].plot(ts, sim['f_ext'][:, 2], label='f_ext')\n",
    "                ax[2].set_ylabel('τ')\n",
    "                ax[2].set_xlabel('t')\n",
    "                ax[2].legend()\n",
    "\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(os.path.join(model_dir, 'figs/estimation_{}'.format(filename.replace('.pkl', '.png'))))\n",
    "                plt.close(fig)\n",
    "\n",
    "    sim['ts'] = ts\n",
    "    test = {\n",
    "            'sim': sim,\n",
    "            'params': test_params,\n",
    "            'results': test_results,\n",
    "            }\n",
    "    if save_dir is not None:\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        with open(os.path.join(save_dir, 'test_' + filename), 'wb') as f:\n",
    "            pickle.dump(test, f)\n",
    "\n",
    "    return sim, test_params, test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "\n",
    "def eval_dir_models_fig(model_dir, T, dt, w, pnorm_flag=True, visual_verbose=0, save_dir=None, fixed_P=None):\n",
    "    if fixed_P == None:\n",
    "        csv_file_path = os.path.join(model_dir, 'model_test_results.csv')\n",
    "    else:\n",
    "        csv_file_path = os.path.join(model_dir, 'model_test_results_fixed_P_{}.csv'.format(fixed_P))\n",
    "    Header = ['Seed', 'M', 'Epoch', 'init_p', 'p_freq', 'reg_P', 'best_step', 'final_p', 'Test Tracking Error', 'Test Estimation Error', 'Frob(P)', 'Loss plot', 'Trajectory plot', 'Estimation plot']\n",
    "    with open(csv_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write the header\n",
    "        writer.writerow(Header)\n",
    "\n",
    "        for filename in tqdm(os.listdir(model_dir)):\n",
    "            if filename.endswith(\".pkl\"):\n",
    "                model_sim, model_test_params, model_test_results = eval_single_model(model_dir, filename, T, dt, w, pnorm_flag, visual_verbose, save_dir=save_dir, fixed_P=fixed_P)\n",
    "                global_path = '/Users/sunbochentang/Documents/Local_Project/Research/COML/COML_Ablation'\n",
    "                fig1_path = os.path.join(global_path, model_dir, 'figs/train_info_{}'.format(filename.replace('.pkl', '.png')))\n",
    "                fig2_path = os.path.join(global_path, model_dir, 'figs/tracking_{}'.format(filename.replace('.pkl', '.png')))\n",
    "                fig3_path = os.path.join(global_path, model_dir, 'figs/estimation_{}'.format(filename.replace('.pkl', '.png')))\n",
    "                # Write the results to the csv file\n",
    "                row = [model_test_results['train_params']['seed'], model_test_results['train_params']['M'], model_test_results['train_params']['E'], model_test_results['train_params']['pinit'], model_test_results['train_params']['pfreq'], model_test_results['train_params']['regP'], model_test_results['train_info']['best_step_meta'], model_test_results['final_p'], model_test_results['tracking_err'], model_test_results['estimation_err'], np.linalg.norm(model_test_params['P'])]\n",
    "                if visual_verbose > 0:\n",
    "                    fig1_url = 'file://' + urllib.parse.quote(fig1_path)\n",
    "                    row.append(fig1_url)\n",
    "                    if visual_verbose > 1:\n",
    "                        fig2_url = 'file://' + urllib.parse.quote(fig2_path)\n",
    "                        row.append(fig2_url)\n",
    "                        if visual_verbose > 2:\n",
    "                            fig3_url = 'file://' + urllib.parse.quote(fig3_path)\n",
    "                            row.append(fig3_url)\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim, test_params, test_results = eval_single_model('train_results/new_pnorm_test', 'seed=0_M=10_E=500_pinit=2.00_pfreq=1000_regP=0.0000.pkl', T=10, dt=0.02, w=6.5, pnorm_flag=True, visual_verbose=3, save_dir=None, fixed_P=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim, test_params, test_results = eval_single_model('train_results/new_pnorm_test', 'seed=0_M=10_E=500_pinit=2.00_pfreq=1000_regP=0.0000.pkl', T=10, dt=0.02, w=6.5, pnorm_flag=True, visual_verbose=3, save_dir=None, fixed_P=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 3.4547436e+00,  1.2715840e-01, -6.9612940e-03],\n",
       "       [ 1.2715840e-01,  3.7698278e+00, -1.5210855e-03],\n",
       "       [-6.9612940e-03, -1.5210855e-03,  1.6587613e+00]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_params['P']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Model Performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that compares models with same parameter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
