{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josh/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO description.\n",
    "\n",
    "Author: Spencer M. Richards\n",
    "        Autonomous Systems Lab (ASL), Stanford\n",
    "        (GitHub: spenrich)\n",
    "\"\"\"\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "from functools import partial\n",
    "import time\n",
    "import warnings\n",
    "from math import pi, inf\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from jax import config\n",
    "config.update(\"jax_debug_nans\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args_class:\n",
    "    def __init__(self, seed, M, pnorm_init, p_freq, meta_epochs, reg_P, output_dir, use_x64):\n",
    "        self.seed = seed\n",
    "        self.M = M\n",
    "        self.pnorm_init = pnorm_init\n",
    "        self.p_freq = p_freq\n",
    "        self.meta_epochs = meta_epochs\n",
    "        self.reg_P = reg_P\n",
    "        self.output_dir = output_dir\n",
    "        self.use_x64 = use_x64\n",
    "\n",
    "args = args_class(0, 25, 2.0, 50, 4000, 2e-3, 'diagnose_regP', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Parse command line arguments\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('seed', help='seed for pseudo-random number generation',\n",
    "#                     type=int)\n",
    "# parser.add_argument('M', help='number of trajectories to sub-sample',\n",
    "#                     type=int)\n",
    "# parser.add_argument('--use_x64', help='use 64-bit precision',\n",
    "#                     action='store_true')\n",
    "# parser.add_argument('--pnorm_init', help='set initial value for p-norm choices', type=float)\n",
    "# parser.add_argument('--p_freq', help='set frequency for p-norm parameter update', type=float)\n",
    "# parser.add_argument('--meta_epochs', help='set number of epochs for meta-training', type=int)\n",
    "# parser.add_argument('--reg_P', help='set regularization for P matrix', type=float)\n",
    "# parser.add_argument('--output_dir', help='set output directory', type=str)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# Set precision\n",
    "if args.use_x64:\n",
    "    os.environ['JAX_ENABLE_X64'] = 'True'\n",
    "\n",
    "import jax                                          # noqa: E402\n",
    "import jax.numpy as jnp                             # noqa: E402\n",
    "from jax.example_libraries import optimizers             # noqa: E402\n",
    "from dynamics import prior                          # noqa: E402\n",
    "from utils import (tree_normsq, rk38_step, epoch,   # noqa: E402\n",
    "                   odeint_fixed_step, random_ragged_spline, spline,\n",
    "            params_to_cholesky, params_to_posdef, \n",
    "            quaternion_to_rotation_matrix, hat, vee)\n",
    "\n",
    "import jax.debug as jdebug\n",
    "\n",
    "def convert_p_qbar(p):\n",
    "    return jnp.sqrt(1/(1 - 1/p) - 1.1)\n",
    "\n",
    "def convert_qbar_p(qbar):\n",
    "    return 1/(1 - 1/(1.1 + qbar**2))\n",
    "\n",
    "# Initialize PRNG key\n",
    "key = jax.random.PRNGKey(args.seed)\n",
    "\n",
    "# Hyperparameters\n",
    "hparams = {\n",
    "    'seed':        args.seed,     #\n",
    "    'use_x64':     args.use_x64,  #\n",
    "    'num_subtraj': args.M,        # number of trajectories to sub-sample\n",
    "\n",
    "    # For training the model ensemble\n",
    "    'ensemble': {\n",
    "        'num_hlayers':    2,     # number of hidden layers in each model\n",
    "        'hdim':           32,    # number of hidden units per layer\n",
    "        'train_frac':     0.75,  # fraction of each trajectory for training\n",
    "        'batch_frac':     0.25,  # fraction of training data per batch\n",
    "        'regularizer_l2': 1e-4,  # coefficient for L2-regularization\n",
    "        'learning_rate':  1e-2,  # step size for gradient optimization\n",
    "        'num_epochs':     1000,  # number of epochs\n",
    "    },\n",
    "    # For meta-training\n",
    "    'meta': {\n",
    "        'num_hlayers':       2,          # number of hidden layers\n",
    "        'hdim':              32,         # number of hidden units per layer\n",
    "        'train_frac':        0.75,       #\n",
    "        'learning_rate':     1e-2,       # step size for gradient optimization\n",
    "        'num_steps':         args.meta_epochs,        # maximum number of gradient steps\n",
    "        'regularizer_l2':    1e-4,       # coefficient for L2-regularization\n",
    "        'regularizer_ctrl':  1e-3,       #\n",
    "        'regularizer_error': 0.,         #\n",
    "        'T':                 5.,         # time horizon for each reference\n",
    "        'dt':                1e-2,       # time step for numerical integration\n",
    "        'num_refs':          10,         # reference trajectories to generate\n",
    "        'num_knots':         6,          # knot points per reference spline\n",
    "        'poly_orders':       (9, 9, 9),  # spline orders for each DOF\n",
    "        'deriv_orders':      (4, 4, 4),  # smoothness objective for each DOF\n",
    "        'min_step':          (-2., -2., -0.75),    #\n",
    "        'max_step':          (2., 2., 0.75),       #\n",
    "        'min_ref':           (-inf, -inf, -inf),  #\n",
    "        'max_ref':           (inf, inf, inf),     #\n",
    "        'p_freq':            args.p_freq,          # frequency for p-norm update\n",
    "        'regularizer_P':     args.reg_P,           # coefficient for P regularization\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PROCESSING ########################################################\n",
    "# Load raw data and arrange in samples of the form\n",
    "# `(t, x, u, t_next, x_next)` for each trajectory, where `x := (q,dq)`\n",
    "with open('data/2024-04-04_23-51-17_traj50_seed0.pkl', 'rb') as file:\n",
    "    raw = pickle.load(file)\n",
    "num_dof = raw['q'].shape[-1]       # number of degrees of freedom\n",
    "param_dim = 2*num_dof + 9 + 3    # number of degrees of freedom including attitude (9 for rotation matrix, 3 for angular velocity)\n",
    "num_traj = raw['q'].shape[0]       # total number of raw trajectories\n",
    "num_samples = raw['t'].size - 1    # number of transitions per trajectory\n",
    "t = jnp.tile(raw['t'][:-1], (num_traj, 1))\n",
    "t_next = jnp.tile(raw['t'][1:], (num_traj, 1))\n",
    "x = jnp.concatenate((raw['q'][:, :-1], raw['dq'][:, :-1]), axis=-1)\n",
    "x_next = jnp.concatenate((raw['q'][:, 1:], raw['dq'][:, 1:]), axis=-1)\n",
    "u = raw['u'][:, :-1, :3]\n",
    "quat = raw['quat'][:, :-1]\n",
    "R = jax.vmap(jax.vmap(quaternion_to_rotation_matrix, in_axes=0), in_axes=0)(quat)\n",
    "R_flatten = R.reshape(R.shape[0], R.shape[1], -1)\n",
    "omega = raw['omega'][:, :-1]\n",
    "data = {'t': t, 'x': x, 'u': u, 'R_flatten': R_flatten, 'omega': omega, 't_next': t_next, 'x_next': x_next}\n",
    "\n",
    "# Shuffle and sub-sample trajectories\n",
    "if hparams['num_subtraj'] > num_traj:\n",
    "    warnings.warn('Cannot sub-sample {:d} trajectories! '\n",
    "                    'Capping at {:d}.'.format(hparams['num_subtraj'],\n",
    "                                            num_traj))\n",
    "    hparams['num_subtraj'] = num_traj\n",
    "\n",
    "key, subkey = jax.random.split(key, 2)\n",
    "shuffled_idx = jax.random.permutation(subkey, num_traj)\n",
    "hparams['subtraj_idx'] = shuffled_idx[:hparams['num_subtraj']]\n",
    "data = jax.tree_util.tree_map(\n",
    "    lambda a: jnp.take(a, hparams['subtraj_idx'], axis=0),\n",
    "    data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENSEMBLE TRAINING: Pre-compiling ... done (0.93 s)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [12:34<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# MODEL ENSEMBLE TRAINING ################################################\n",
    "# Loss function along a trajectory\n",
    "def ode(x, R_flatten, omega, t, u, params, prior=prior):\n",
    "    \"\"\"TODO: docstring.\"\"\"\n",
    "    num_dof = x.size // 2\n",
    "    q, dq = x[:num_dof], x[num_dof:]\n",
    "    H, C, g, B = prior(q, dq)\n",
    "\n",
    "    # Each model in the ensemble is a feed-forward neural network\n",
    "    # with zero output bias\n",
    "    f_ext = x\n",
    "    f_ext = jnp.concatenate([f_ext, R_flatten, omega], axis=0)\n",
    "    for W, b in zip(params['W'], params['b']):\n",
    "        f_ext = jnp.tanh(W@f_ext + b)\n",
    "    f_ext = params['A'] @ f_ext\n",
    "    ddq = jax.scipy.linalg.solve(H, B@u + f_ext - C@dq - g, assume_a='pos')\n",
    "    dx = jnp.concatenate((dq, ddq))\n",
    "    return dx\n",
    "\n",
    "def loss(params, regularizer, t, x, R_flatten, omega, u, t_next, x_next, ode=ode):\n",
    "    \"\"\"TODO: docstring.\"\"\"\n",
    "    num_samples = t.size\n",
    "    dt = t_next - t\n",
    "    x_next_est = jax.vmap(rk38_step, (None, 0, 0, 0, 0, 0, 0, None))(\n",
    "        ode, dt, x, R_flatten, omega, t, u, params\n",
    "    )\n",
    "    loss = (jnp.sum((x_next_est - x_next)**2)\n",
    "            + regularizer*tree_normsq(params)) / num_samples\n",
    "    return loss\n",
    "\n",
    "# Parallel updates for each model in the ensemble\n",
    "@partial(jax.jit, static_argnums=(4, 5))\n",
    "@partial(jax.vmap, in_axes=(None, 0, None, 0, None, None))\n",
    "def step(idx, opt_state, regularizer, batch, get_params, update_opt,\n",
    "            loss=loss):\n",
    "    \"\"\"TODO: docstring.\"\"\"\n",
    "    params = get_params(opt_state)\n",
    "    grads = jax.grad(loss, argnums=0)(params, regularizer, **batch)\n",
    "    opt_state = update_opt(idx, grads, opt_state)\n",
    "    return opt_state\n",
    "\n",
    "@jax.jit\n",
    "@jax.vmap\n",
    "def update_best_ensemble(old_params, old_loss, new_params, batch):\n",
    "    \"\"\"TODO: docstring.\"\"\"\n",
    "    new_loss = loss(new_params, 0., **batch)  # do not regularize\n",
    "    best_params = jax.tree_util.tree_map(\n",
    "        lambda x, y: jnp.where(new_loss < old_loss, x, y),\n",
    "        new_params,\n",
    "        old_params\n",
    "    )\n",
    "    best_loss = jnp.where(new_loss < old_loss, new_loss, old_loss)\n",
    "    return best_params, best_loss, new_loss\n",
    "\n",
    "# Initialize model parameters\n",
    "num_models = hparams['num_subtraj']  # one model per trajectory\n",
    "num_hlayers = hparams['ensemble']['num_hlayers']\n",
    "hdim = hparams['ensemble']['hdim']\n",
    "if num_hlayers >= 1:\n",
    "    shapes = [(hdim, param_dim), ] + (num_hlayers-1)*[(hdim, hdim), ]\n",
    "else:\n",
    "    shapes = []\n",
    "key, *subkeys = jax.random.split(key, 1 + 2*num_hlayers + 1)\n",
    "keys_W = subkeys[:num_hlayers]\n",
    "keys_b = subkeys[num_hlayers:-1]\n",
    "key_A = subkeys[-1]\n",
    "ensemble = {\n",
    "    # hidden layer weights\n",
    "    'W': [0.1*jax.random.normal(keys_W[i], (num_models, *shapes[i]))\n",
    "            for i in range(num_hlayers)],\n",
    "    # hidden layer biases\n",
    "    'b': [0.1*jax.random.normal(keys_b[i], (num_models, shapes[i][0]))\n",
    "            for i in range(num_hlayers)],\n",
    "    # last layer weights\n",
    "    'A': 0.1*jax.random.normal(key_A, (num_models, num_dof, hdim))\n",
    "}\n",
    "\n",
    "# Shuffle samples in time along each trajectory, then split each\n",
    "# trajectory into training and validation sets (i.e., for each model)\n",
    "key, *subkeys = jax.random.split(key, 1 + num_models)\n",
    "subkeys = jnp.asarray(subkeys)\n",
    "shuffled_data = jax.tree_util.tree_map(\n",
    "    lambda a: jax.vmap(jax.random.permutation)(subkeys, a),\n",
    "    data\n",
    ")\n",
    "num_train_samples = int(hparams['ensemble']['train_frac'] * num_samples)\n",
    "ensemble_train_data = jax.tree_util.tree_map(\n",
    "    lambda a: a[:, :num_train_samples],\n",
    "    shuffled_data\n",
    ")\n",
    "ensemble_valid_data = jax.tree_util.tree_map(\n",
    "    lambda a: a[:, num_train_samples:],\n",
    "    shuffled_data\n",
    ")\n",
    "\n",
    "# Initialize gradient-based optimizer (ADAM)\n",
    "learning_rate = hparams['ensemble']['learning_rate']\n",
    "batch_size = int(hparams['ensemble']['batch_frac'] * num_train_samples)\n",
    "num_batches = num_train_samples // batch_size\n",
    "init_opt, update_opt, get_params = optimizers.adam(learning_rate)\n",
    "opt_states = jax.vmap(init_opt)(ensemble)\n",
    "get_ensemble = jax.jit(jax.vmap(get_params))\n",
    "step_idx = 0\n",
    "best_idx = jnp.zeros(num_models)\n",
    "\n",
    "# Pre-compile before training\n",
    "print('ENSEMBLE TRAINING: Pre-compiling ... ', end='', flush=True)\n",
    "start = time.time()\n",
    "batch = next(epoch(key, ensemble_train_data, batch_size,\n",
    "                    batch_axis=1, ragged=False))\n",
    "_ = step(step_idx, opt_states, hparams['ensemble']['regularizer_l2'],\n",
    "            batch, get_params, update_opt)\n",
    "inf_losses = jnp.broadcast_to(jnp.inf, (num_models,))\n",
    "best_ensemble, best_losses, _ = update_best_ensemble(ensemble,\n",
    "                                                        inf_losses,\n",
    "                                                        ensemble,\n",
    "                                                        ensemble_valid_data)\n",
    "_ = get_ensemble(opt_states)\n",
    "end = time.time()\n",
    "print('done ({:.2f} s)!'.format(end - start))\n",
    "\n",
    "# Do gradient descent\n",
    "for _ in tqdm(range(hparams['ensemble']['num_epochs'])):\n",
    "    key, subkey = jax.random.split(key, 2)\n",
    "    for batch in epoch(subkey, ensemble_train_data, batch_size,\n",
    "                        batch_axis=1, ragged=False):\n",
    "        opt_states = step(step_idx, opt_states,\n",
    "                            hparams['ensemble']['regularizer_l2'],\n",
    "                            batch, get_params, update_opt)\n",
    "        new_ensemble = get_ensemble(opt_states)\n",
    "        old_losses = best_losses\n",
    "        best_ensemble, best_losses, valid_losses = update_best_ensemble(\n",
    "            best_ensemble, best_losses, new_ensemble, batch\n",
    "        )\n",
    "        step_idx += 1\n",
    "        best_idx = jnp.where(old_losses == best_losses,\n",
    "                                best_idx, step_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize pnorm as 2.00\n",
      "META-TRAINING: Pre-compiling ... before ode\n",
      "x0: (array(6, dtype=int32),)\n",
      "R_flatten0: (array(9, dtype=int32),)\n",
      "Omega0: (array(3, dtype=int32),)\n",
      "A0: (array(3, dtype=int32), array(32, dtype=int32))\n",
      "c0: (array(3, dtype=int32),)\n",
      "after ode\n",
      "x: (array(18, dtype=int32), array(501, dtype=int32), array(6, dtype=int32))\n",
      "R_flatten: (array(18, dtype=int32), array(501, dtype=int32), array(9, dtype=int32))\n",
      "Omega: (array(18, dtype=int32), array(501, dtype=int32), array(3, dtype=int32))\n",
      "A: (array(18, dtype=int32), array(501, dtype=int32), array(3, dtype=int32), array(32, dtype=int32))\n",
      "c: (array(18, dtype=int32), array(501, dtype=int32), array(3, dtype=int32))\n",
      "begin ode\n",
      "before ode\n",
      "x0: (array(6, dtype=int32),)\n",
      "R_flatten0: (array(9, dtype=int32),)\n",
      "Omega0: (array(3, dtype=int32),)\n",
      "A0: (array(3, dtype=int32), array(32, dtype=int32))\n",
      "c0: (array(3, dtype=int32),)\n",
      "after ode\n",
      "x: (array(18, dtype=int32), array(501, dtype=int32), array(6, dtype=int32))\n",
      "R_flatten: (array(18, dtype=int32), array(501, dtype=int32), array(9, dtype=int32))\n",
      "Omega: (array(18, dtype=int32), array(501, dtype=int32), array(3, dtype=int32))\n",
      "A: (array(18, dtype=int32), array(501, dtype=int32), array(3, dtype=int32), array(32, dtype=int32))\n",
      "c: (array(18, dtype=int32), array(501, dtype=int32), array(3, dtype=int32))\n",
      "begin ode\n"
     ]
    },
    {
     "ename": "FloatingPointError",
     "evalue": "invalid value (nan) encountered in jit(scan)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/jax/_src/profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 314\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/jax/_src/interpreters/pxla.py:1353\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arrays \u001b[38;5;129;01min\u001b[39;00m out_arrays:\n\u001b[0;32m-> 1353\u001b[0m   \u001b[43mdispatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_special\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1354\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_handler(out_arrays)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/jax/_src/dispatch.py:437\u001b[0m, in \u001b[0;36mcheck_special\u001b[0;34m(name, bufs)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m buf \u001b[38;5;129;01min\u001b[39;00m bufs:\n\u001b[0;32m--> 437\u001b[0m   \u001b[43m_check_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/jax/_src/dispatch.py:442\u001b[0m, in \u001b[0;36m_check_special\u001b[0;34m(name, dtype, buf)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_nans \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[0;32m--> 442\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_infs \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(step_meta)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/jax/_src/profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 314\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/jax/_src/interpreters/pxla.py:1353\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arrays \u001b[38;5;129;01min\u001b[39;00m out_arrays:\n\u001b[0;32m-> 1353\u001b[0m   \u001b[43mdispatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_special\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1354\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_handler(out_arrays)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/jax/_src/dispatch.py:437\u001b[0m, in \u001b[0;36mcheck_special\u001b[0;34m(name, bufs)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m buf \u001b[38;5;129;01min\u001b[39;00m bufs:\n\u001b[0;32m--> 437\u001b[0m   \u001b[43m_check_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/jax/_src/dispatch.py:442\u001b[0m, in \u001b[0;36m_check_special\u001b[0;34m(name, dtype, buf)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_nans \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[0;32m--> 442\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_infs \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(loss)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/jax/_src/profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 314\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/jax/_src/interpreters/pxla.py:1353\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arrays \u001b[38;5;129;01min\u001b[39;00m out_arrays:\n\u001b[0;32m-> 1353\u001b[0m   \u001b[43mdispatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_special\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1354\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_handler(out_arrays)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/jax/_src/dispatch.py:437\u001b[0m, in \u001b[0;36mcheck_special\u001b[0;34m(name, bufs)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m buf \u001b[38;5;129;01min\u001b[39;00m bufs:\n\u001b[0;32m--> 437\u001b[0m   \u001b[43m_check_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/jax/_src/dispatch.py:442\u001b[0m, in \u001b[0;36m_check_special\u001b[0;34m(name, dtype, buf)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_nans \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[0;32m--> 442\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_infs \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(odeint_fixed_step)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/jax/_src/profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 314\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/jax/_src/interpreters/pxla.py:1353\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arrays \u001b[38;5;129;01min\u001b[39;00m out_arrays:\n\u001b[0;32m-> 1353\u001b[0m   \u001b[43mdispatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_special\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1354\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_handler(out_arrays)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/jax/_src/dispatch.py:437\u001b[0m, in \u001b[0;36mcheck_special\u001b[0;34m(name, bufs)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m buf \u001b[38;5;129;01min\u001b[39;00m bufs:\n\u001b[0;32m--> 437\u001b[0m   \u001b[43m_check_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/jax/_src/dispatch.py:442\u001b[0m, in \u001b[0;36m_check_special\u001b[0;34m(name, dtype, buf)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_nans \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[0;32m--> 442\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_infs \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(odeint_ckpt)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/jax/_src/profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 314\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/jax/_src/interpreters/pxla.py:1353\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arrays \u001b[38;5;129;01min\u001b[39;00m out_arrays:\n\u001b[0;32m-> 1353\u001b[0m   \u001b[43mdispatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_special\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1354\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_handler(out_arrays)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/jax/_src/dispatch.py:437\u001b[0m, in \u001b[0;36mcheck_special\u001b[0;34m(name, bufs)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m buf \u001b[38;5;129;01min\u001b[39;00m bufs:\n\u001b[0;32m--> 437\u001b[0m   \u001b[43m_check_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/jax/_src/dispatch.py:442\u001b[0m, in \u001b[0;36m_check_special\u001b[0;34m(name, dtype, buf)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_nans \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[0;32m--> 442\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_infs \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(_odeint_ckpt)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJaxStackTraceBeforeTransformation\u001b[0m         Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py:197\u001b[0m, in \u001b[0;36m_run_module_as_main\u001b[0;34m()\u001b[0m\n\u001b[1;32m    196\u001b[0m     sys\u001b[38;5;241m.\u001b[39margv[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m mod_spec\u001b[38;5;241m.\u001b[39morigin\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _run_code(code, main_globals, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    198\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m, mod_spec)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py:87\u001b[0m, in \u001b[0;36m_run_code\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m run_globals\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m mod_name,\n\u001b[1;32m     81\u001b[0m                    \u001b[38;5;18m__file__\u001b[39m \u001b[38;5;241m=\u001b[39m fname,\n\u001b[1;32m     82\u001b[0m                    __cached__ \u001b[38;5;241m=\u001b[39m cached,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m                    __package__ \u001b[38;5;241m=\u001b[39m pkg_name,\n\u001b[1;32m     86\u001b[0m                    __spec__ \u001b[38;5;241m=\u001b[39m mod_spec)\n\u001b[0;32m---> 87\u001b[0m exec(code, run_globals)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run_globals\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ipykernel_launcher.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mipykernel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m kernelapp \u001b[38;5;28;01mas\u001b[39;00m app\n\u001b[0;32m---> 18\u001b[0m app\u001b[38;5;241m.\u001b[39mlaunch_new_instance()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/traitlets/config/application.py:1075\u001b[0m, in \u001b[0;36mlaunch_instance\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1074\u001b[0m app\u001b[38;5;241m.\u001b[39minitialize(argv)\n\u001b[0;32m-> 1075\u001b[0m app\u001b[38;5;241m.\u001b[39mstart()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelapp.py:739\u001b[0m, in \u001b[0;36mstart\u001b[0;34m()\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 739\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio_loop\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tornado/platform/asyncio.py:205\u001b[0m, in \u001b[0;36mstart\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masyncio_loop\u001b[38;5;241m.\u001b[39mrun_forever()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py:596\u001b[0m, in \u001b[0;36mrun_forever\u001b[0;34m()\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_once()\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py:1890\u001b[0m, in \u001b[0;36m_run_once\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1889\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1890\u001b[0m         handle\u001b[38;5;241m.\u001b[39m_run()\n\u001b[1;32m   1891\u001b[0m handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/events.py:80\u001b[0m, in \u001b[0;36m_run\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSystemExit\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py:545\u001b[0m, in \u001b[0;36mdispatch_queue\u001b[0;34m()\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 545\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_one()\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py:534\u001b[0m, in \u001b[0;36mprocess_one\u001b[0;34m()\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 534\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m dispatch(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py:437\u001b[0m, in \u001b[0;36mdispatch_shell\u001b[0;34m()\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m--> 437\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m result\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py:362\u001b[0m, in \u001b[0;36mexecute_request\u001b[0;34m()\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_associate_new_top_level_threads_with(parent_header)\n\u001b[0;32m--> 362\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mexecute_request(stream, ident, parent)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py:778\u001b[0m, in \u001b[0;36mexecute_request\u001b[0;34m()\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(reply_content):\n\u001b[0;32m--> 778\u001b[0m     reply_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m reply_content\n\u001b[1;32m    780\u001b[0m \u001b[38;5;66;03m# Flush output before sending the reply.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py:449\u001b[0m, in \u001b[0;36mdo_execute\u001b[0;34m()\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accepts_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 449\u001b[0m     res \u001b[38;5;241m=\u001b[39m shell\u001b[38;5;241m.\u001b[39mrun_cell(\n\u001b[1;32m    450\u001b[0m         code,\n\u001b[1;32m    451\u001b[0m         store_history\u001b[38;5;241m=\u001b[39mstore_history,\n\u001b[1;32m    452\u001b[0m         silent\u001b[38;5;241m=\u001b[39msilent,\n\u001b[1;32m    453\u001b[0m         cell_id\u001b[38;5;241m=\u001b[39mcell_id,\n\u001b[1;32m    454\u001b[0m     )\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ipykernel/zmqshell.py:549\u001b[0m, in \u001b[0;36mrun_cell\u001b[0;34m()\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrun_cell(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py:3048\u001b[0m, in \u001b[0;36mrun_cell\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3047\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3048\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_cell(\n\u001b[1;32m   3049\u001b[0m         raw_cell, store_history, silent, shell_futures, cell_id\n\u001b[1;32m   3050\u001b[0m     )\n\u001b[1;32m   3051\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py:3103\u001b[0m, in \u001b[0;36m_run_cell\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3103\u001b[0m     result \u001b[38;5;241m=\u001b[39m runner(coro)\n\u001b[1;32m   3104\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/async_helpers.py:129\u001b[0m, in \u001b[0;36m_pseudo_sync_runner\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py:3308\u001b[0m, in \u001b[0;36mrun_cell_async\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3305\u001b[0m interactivity \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m silent \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mast_node_interactivity\n\u001b[0;32m-> 3308\u001b[0m has_raised \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_ast_nodes(code_ast\u001b[38;5;241m.\u001b[39mbody, cell_name,\n\u001b[1;32m   3309\u001b[0m        interactivity\u001b[38;5;241m=\u001b[39minteractivity, compiler\u001b[38;5;241m=\u001b[39mcompiler, result\u001b[38;5;241m=\u001b[39mresult)\n\u001b[1;32m   3311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_execution_succeeded \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m has_raised\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py:3490\u001b[0m, in \u001b[0;36mrun_ast_nodes\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3489\u001b[0m     asy \u001b[38;5;241m=\u001b[39m compare(code)\n\u001b[0;32m-> 3490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_code(code, result, async_\u001b[38;5;241m=\u001b[39masy):\n\u001b[1;32m   3491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py:3550\u001b[0m, in \u001b[0;36mrun_code\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3549\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3550\u001b[0m         exec(code_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_global_ns, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns)\n\u001b[1;32m   3551\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   3552\u001b[0m     \u001b[38;5;66;03m# Reset our crash handler in place\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[42], line 328\u001b[0m\n\u001b[1;32m    327\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 328\u001b[0m _ \u001b[38;5;241m=\u001b[39m step_meta(\u001b[38;5;241m0\u001b[39m, opt_meta, pnorm_param, train_ensemble, train_t_knots, train_coefs, T, dt, regularizer_l2, regularizer_ctrl, regularizer_error, regularizer_P)\n\u001b[1;32m    329\u001b[0m _ \u001b[38;5;241m=\u001b[39m step_pnorm(\u001b[38;5;241m0\u001b[39m, meta_params, opt_pnorm, train_ensemble, train_t_knots, train_coefs, T, dt, regularizer_l2, regularizer_ctrl, regularizer_error, regularizer_P)\n",
      "Cell \u001b[0;32mIn[42], line 301\u001b[0m, in \u001b[0;36mstep_meta\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m meta_params \u001b[38;5;241m=\u001b[39m get_params(opt_state)\n\u001b[0;32m--> 301\u001b[0m grads, aux \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mgrad(loss, argnums\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    302\u001b[0m     meta_params, pnorm_param, ensemble_params, t_knots, coefs, T, dt,\n\u001b[1;32m    303\u001b[0m     regularizer_l2, regularizer_ctrl, regularizer_error, regularizer_P\n\u001b[1;32m    304\u001b[0m )\n\u001b[1;32m    305\u001b[0m opt_state \u001b[38;5;241m=\u001b[39m update_opt(idx, grads, opt_state)\n",
      "Cell \u001b[0;32mIn[42], line 221\u001b[0m, in \u001b[0;36mloss\u001b[0;34m()\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# Simulate on each model for each reference trajectory\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m t, x, R_flatten, Omega, A, c \u001b[38;5;241m=\u001b[39m simulate(meta_params, pnorm_param, ensemble_params, t_knots,\n\u001b[1;32m    222\u001b[0m                         coefs, T, dt)\n\u001b[1;32m    224\u001b[0m \u001b[38;5;66;03m# Sum final costs over reference trajectories and ensemble models\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Note `c` has shape (`num_refs`, `num_models`, `T // dt`, 3)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[42], line 212\u001b[0m, in \u001b[0;36msimulate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n\u001b[0;32m--> 212\u001b[0m t, x, R_flatten, Omega, A, c \u001b[38;5;241m=\u001b[39m ensemble_sim(meta_params, pnorm_param, ensemble_params,\n\u001b[1;32m    213\u001b[0m                             reference, T, dt)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m t, x, R_flatten, Omega, A, c\n",
      "Cell \u001b[0;32mIn[42], line 132\u001b[0m, in \u001b[0;36mensemble_sim\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# jdebug.print('z0: {}', len(z0))\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m z, t \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(odeint_fixed_step, in_axes)(ode, z0, \u001b[38;5;241m0.\u001b[39m, T, dt,\n\u001b[1;32m    133\u001b[0m                                             meta_params, pnorm_param,\n\u001b[1;32m    134\u001b[0m                                             ensemble_params)\n\u001b[1;32m    135\u001b[0m jdebug\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter ode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/r/COML_hardware/utils.py:392\u001b[0m, in \u001b[0;36modeint_fixed_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m    391\u001b[0m ts \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mlinspace(t0, t1, num_steps \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 392\u001b[0m xs \u001b[38;5;241m=\u001b[39m odeint_ckpt(func, x0, ts, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xs, ts\n",
      "File \u001b[0;32m~/r/COML_hardware/utils.py:378\u001b[0m, in \u001b[0;36modeint_ckpt\u001b[0;34m()\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# Solve in flat form\u001b[39;00m\n\u001b[0;32m--> 378\u001b[0m flat_xs \u001b[38;5;241m=\u001b[39m _odeint_ckpt(flat_func, flat_x0, ts, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    379\u001b[0m xs \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(unravel)(flat_xs)\n",
      "File \u001b[0;32m~/r/COML_hardware/utils.py:362\u001b[0m, in \u001b[0;36m_odeint_ckpt\u001b[0;34m()\u001b[0m\n\u001b[1;32m    361\u001b[0m init_carry \u001b[38;5;241m=\u001b[39m (x0, ts[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39margs)  \u001b[38;5;66;03m# dummy state at same time as `t0`\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m carry, xs \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mlax\u001b[38;5;241m.\u001b[39mscan(scan_fun, init_carry, ts)\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xs\n",
      "\u001b[0;31mJaxStackTraceBeforeTransformation\u001b[0m: FloatingPointError: invalid value (nan) encountered in jit(scan)\n\nThe preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.\n\n--------------------",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 328\u001b[0m\n\u001b[1;32m    326\u001b[0m regularizer_P \u001b[38;5;241m=\u001b[39m hparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregularizer_P\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    327\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 328\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mstep_meta\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_meta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpnorm_param\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ensemble\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_t_knots\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_coefs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregularizer_l2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregularizer_ctrl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregularizer_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregularizer_P\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m _ \u001b[38;5;241m=\u001b[39m step_pnorm(\u001b[38;5;241m0\u001b[39m, meta_params, opt_pnorm, train_ensemble, train_t_knots, train_coefs, T, dt, regularizer_l2, regularizer_ctrl, regularizer_error, regularizer_P)\n\u001b[1;32m    330\u001b[0m _ \u001b[38;5;241m=\u001b[39m loss(meta_params, pnorm_param, valid_ensemble, valid_t_knots, valid_coefs, T, dt,\n\u001b[1;32m    331\u001b[0m             \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 19 frame]\u001b[0m\n",
      "    \u001b[0;31m[... skipping similar frames: _pjit_call_impl at line 1203 (2 times), _pjit_call_impl_python at line 1147 (2 times), AxisPrimitive.bind at line 2677 (2 times), Primitive.bind_with_trace at line 383 (2 times), _pjit_call_impl.<locals>.call_impl_cache_miss at line 1187 (2 times), eval_jaxpr at line 448 (2 times), jaxpr_as_fun at line 229 (2 times), EvalTrace.process_primitive at line 815 (2 times)]\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 16 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/jax/_src/dispatch.py:442\u001b[0m, in \u001b[0;36m_check_special\u001b[0;34m(name, dtype, buf)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39missubdtype(dtype, np\u001b[38;5;241m.\u001b[39minexact):\n\u001b[1;32m    441\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_nans \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    443\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_infs \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (inf) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(scan)"
     ]
    }
   ],
   "source": [
    "# META-TRAINING ##########################################################\n",
    "def ode(z, t, meta_params, pnorm_param, params, reference, prior=prior):\n",
    "    \"\"\"TODO: docstring.\"\"\"\n",
    "    jdebug.print('begin ode')\n",
    "    jdebug.print('z input: {}', z)\n",
    "    \n",
    "    x, R_flatten, Omega, pA, c = z\n",
    "    num_dof = x.size // 2\n",
    "    q, dq = x[:num_dof], x[num_dof:]\n",
    "    r = reference(t)\n",
    "    dr = jax.jacfwd(reference)(t)\n",
    "    ddr = jax.jacfwd(jax.jacfwd(reference))(t)\n",
    "\n",
    "    # Regressor features\n",
    "    y = x\n",
    "    y = jnp.concatenate([y, R_flatten, Omega], axis=0)\n",
    "    for W, b in zip(meta_params['W'], meta_params['b']):\n",
    "        y = jnp.tanh(W@y + b)\n",
    "\n",
    "    # Parameterized control and adaptation gains\n",
    "    gains = jax.tree_util.tree_map(\n",
    "        lambda x: params_to_posdef(x),\n",
    "        meta_params['gains']\n",
    "    )\n",
    "    Λ, K, P = gains['Λ'], gains['K'], gains['P']\n",
    "\n",
    "    qn = 1.1 + pnorm_param['pnorm']**2\n",
    "\n",
    "    # A = jax.scipy.linalg.sqrtm(P) @ (jnp.maximum(jnp.abs(pA), 1e-6 * jnp.ones_like(pA))**(qn-1) * jnp.sign(pA) * (jnp.ones_like(pA) - jnp.isclose(pA, 0, atol=1e-6)))\n",
    "    # Previous implementation P size: feature_size x feature_size\n",
    "    A = (jnp.maximum(jnp.abs(pA), 1e-6 * jnp.ones_like(pA))**(qn-1) * jnp.sign(pA) * (jnp.ones_like(pA) - jnp.isclose(pA, 0, atol=1e-6))) @ P\n",
    "    \n",
    "\n",
    "    # Auxiliary signals\n",
    "    e, de = q - r, dq - dr\n",
    "    v, dv = dr - Λ@e, ddr - Λ@de\n",
    "    s = de + Λ@e\n",
    "\n",
    "    # Controller and adaptation law\n",
    "    H, C, g, B = prior(q, dq)\n",
    "    f_ext_hat = A@y\n",
    "    τ = H@dv + C@v + g - f_ext_hat - K@s\n",
    "    u_d = jnp.linalg.solve(B, τ)\n",
    "    # dA = jax.scipy.linalg.sqrtm(P) @ jnp.outer(s, y)\n",
    "    dA = jnp.outer(s, y) @ P\n",
    "\n",
    "    R = R_flatten.reshape((3,3))\n",
    "\n",
    "    f_d = jnp.linalg.norm(u_d)\n",
    "    b_3d = -u_d / jnp.linalg.norm(u_d)\n",
    "    b_1d = jnp.array([1, 0, 0])\n",
    "    cross = jnp.cross(b_3d, b_1d)\n",
    "    b_2d = cross / jnp.linalg.norm(cross)\n",
    "\n",
    "    R_d = jnp.column_stack((jnp.cross(b_2d, b_3d), b_2d, b_3d))\n",
    "\n",
    "    Omega_d = jnp.array([0, 0, 0])\n",
    "    dOmega_d = jnp.array([0, 0, 0])\n",
    "\n",
    "    k_R = jnp.array([1400.0, 1400.0, 1260.0])\n",
    "    k_Omega = jnp.array([330.0, 330.0, 300.0])\n",
    "    J = jnp.diag(jnp.array([0.03, 0.03, 0.09]))\n",
    "\n",
    "    e_R = 0.5 * vee(R_d.T@R - R.T@R_d)\n",
    "    e_Omega = Omega - R.T@R_d@Omega_d\n",
    "\n",
    "    M = - k_R*e_R \\\n",
    "        - k_Omega*e_Omega \\\n",
    "        + jnp.cross(Omega, J@Omega) \\\n",
    "        - J@(hat(Omega)@R.T@R_d@Omega_d - R.T@R_d@dOmega_d)\n",
    "\n",
    "    dOmega = jax.scipy.linalg.solve(J, M - jnp.cross(Omega, J@Omega), assume_a='pos')\n",
    "    dR = R@hat(Omega)\n",
    "    dR_flatten = dR.flatten()\n",
    "\n",
    "    e_3 = jnp.array([0, 0, 1])\n",
    "    u = -f_d*R@e_3\n",
    "\n",
    "    # Apply control to \"true\" dynamics\n",
    "    f_ext = x\n",
    "    f_ext = jnp.concatenate([f_ext, R_flatten, Omega], axis=0)\n",
    "    for W, b in zip(params['W'], params['b']):\n",
    "        f_ext = jnp.tanh(W@f_ext + b)\n",
    "    f_ext = params['A'] @ f_ext\n",
    "    ddq = jax.scipy.linalg.solve(H, u + f_ext - C@dq - g, assume_a='pos')\n",
    "    dx = jnp.concatenate((dq, ddq))\n",
    "\n",
    "    # Estimation loss\n",
    "    # chol_P = params_to_cholesky(meta_params['gains']['P'])\n",
    "    # f_error = f_hat - f\n",
    "    # loss_est = f_error@jax.scipy.linalg.cho_solve((chol_P, True),\n",
    "    #                                               f_error)\n",
    "\n",
    "    # Integrated cost terms\n",
    "    dc = jnp.array([\n",
    "        e@e + de@de,                # tracking loss\n",
    "        u_d@u_d,                        # control loss\n",
    "        (f_ext_hat - f_ext)@(f_ext_hat - f_ext),    # estimation loss\n",
    "    ])\n",
    "\n",
    "    # Assemble derivatives\n",
    "    dz = (dx, dR_flatten, dOmega, dA, dc)\n",
    "    jdebug.print('dx: {}', dx)\n",
    "    return dz\n",
    "\n",
    "# Simulate adaptive control loop on each model in the ensemble\n",
    "def ensemble_sim(meta_params, pnorm_param, ensemble_params, reference, T, dt, ode=ode):\n",
    "    \"\"\"TODO: docstring.\"\"\"\n",
    "    # Initial conditions\n",
    "    r0 = reference(0.)\n",
    "    dr0 = jax.jacfwd(reference)(0.)\n",
    "    num_dof = r0.size\n",
    "    num_features = meta_params['W'][-1].shape[0]\n",
    "    x0 = jnp.concatenate((r0, dr0))\n",
    "    R_flatten0 = jnp.zeros(9)\n",
    "    Omega0 = jnp.zeros(3)\n",
    "    A0 = jnp.zeros((num_dof, num_features))\n",
    "    c0 = jnp.zeros(3)\n",
    "    z0 = (x0, R_flatten0, Omega0, A0, c0)\n",
    "\n",
    "    # Integrate the adaptive control loop using the meta-model\n",
    "    # and EACH model in the ensemble along the same reference\n",
    "    in_axes = (None, None, None, None, None, None, None, 0)\n",
    "    ode = partial(ode, reference=reference)\n",
    "    jdebug.print('before ode')\n",
    "    jdebug.print('x0: {}', x0.shape)\n",
    "    jdebug.print('R_flatten0: {}', R_flatten0.shape)\n",
    "    jdebug.print('Omega0: {}', Omega0.shape)\n",
    "    jdebug.print('A0: {}', A0.shape)\n",
    "    jdebug.print('c0: {}', c0.shape)\n",
    "    # jdebug.print('z0: {}', len(z0))\n",
    "    z, t = jax.vmap(odeint_fixed_step, in_axes)(ode, z0, 0., T, dt,\n",
    "                                                meta_params, pnorm_param,\n",
    "                                                ensemble_params)\n",
    "    jdebug.print('after ode')\n",
    "    x, R_flatten, Omega, A, c = z\n",
    "    jdebug.print('x: {}', x.shape)\n",
    "    jdebug.print('R_flatten: {}', R_flatten.shape)\n",
    "    jdebug.print('Omega: {}', Omega.shape)\n",
    "    jdebug.print('A: {}', A.shape)\n",
    "    jdebug.print('c: {}', c.shape)\n",
    "    # jdebug.print('z output: {}', len(z))\n",
    "    return t, x, R_flatten, Omega, A, c\n",
    "\n",
    "# Initialize meta-model parameters\n",
    "num_hlayers = hparams['meta']['num_hlayers']\n",
    "hdim = hparams['meta']['hdim']\n",
    "if num_hlayers >= 1:\n",
    "    shapes = [(hdim, param_dim), ] + (num_hlayers-1)*[(hdim, hdim), ]\n",
    "else:\n",
    "    shapes = []\n",
    "key, *subkeys = jax.random.split(key, 1 + 2*num_hlayers + 3)\n",
    "subkeys_W = subkeys[:num_hlayers]\n",
    "subkeys_b = subkeys[num_hlayers:-3]\n",
    "subkeys_gains = subkeys[-3:]\n",
    "meta_params = {\n",
    "    # hidden layer weights\n",
    "    'W': [0.1*jax.random.normal(subkeys_W[i], shapes[i])\n",
    "            for i in range(num_hlayers)],\n",
    "    # hidden layer biases\n",
    "    'b': [0.1*jax.random.normal(subkeys_b[i], (shapes[i][0],))\n",
    "            for i in range(num_hlayers)],\n",
    "    'gains': {  # vectorized control and adaptation gains\n",
    "        'Λ': 0.1*jax.random.normal(subkeys_gains[0],\n",
    "                                    ((num_dof*(num_dof + 1)) // 2,)),\n",
    "        'K': 0.1*jax.random.normal(subkeys_gains[1],\n",
    "                                    ((num_dof*(num_dof + 1)) // 2,)),\n",
    "        'P': 0.1*jax.random.normal(subkeys_gains[2],\n",
    "                                    ((hdim*(hdim + 1)) // 2,)),\n",
    "        # 'P': 0.1*jax.random.normal(subkeys_gains[2],\n",
    "                                #    ((num_dof*(num_dof + 1)) // 2,)),\n",
    "    },\n",
    "}\n",
    "# In the bash script, we always specify p-norm desried initial values\n",
    "# Note that the program always uses the q_bar parameter as the p-norm parameterization\n",
    "# However, the printing function should log the final results in p-norm\n",
    "pnorm_param = {'pnorm': convert_p_qbar(args.pnorm_init)}\n",
    "print(\"Initialize pnorm as {:.2f}\".format(convert_qbar_p(pnorm_param['pnorm'])))\n",
    "\n",
    "# Initialize spline coefficients for each reference trajectory\n",
    "num_refs = hparams['meta']['num_refs']\n",
    "key, *subkeys = jax.random.split(key, 1 + num_refs)\n",
    "subkeys = jnp.vstack(subkeys)\n",
    "in_axes = (0, None, None, None, None, None, None, None, None)\n",
    "min_ref = jnp.asarray(hparams['meta']['min_ref'])\n",
    "max_ref = jnp.asarray(hparams['meta']['max_ref'])\n",
    "t_knots, knots, coefs = jax.vmap(random_ragged_spline, in_axes)(\n",
    "    subkeys,\n",
    "    hparams['meta']['T'],\n",
    "    hparams['meta']['num_knots'],\n",
    "    hparams['meta']['poly_orders'],\n",
    "    hparams['meta']['deriv_orders'],\n",
    "    jnp.asarray(hparams['meta']['min_step']),\n",
    "    jnp.asarray(hparams['meta']['max_step']),\n",
    "    0.7*min_ref,\n",
    "    0.7*max_ref,\n",
    ")\n",
    "# x_coefs, y_coefs, θ_coefs = coefs\n",
    "# x_knots, y_knots, θ_knots = knots\n",
    "r_knots = jnp.dstack(knots)\n",
    "\n",
    "# Simulate the adaptive control loop for each model in the ensemble and\n",
    "# each reference trajectory (i.e., spline coefficients)\n",
    "@partial(jax.vmap, in_axes=(None, None, None, 0, 0, None, None))\n",
    "def simulate(meta_params, pnorm_param, ensemble_params, t_knots, coefs, T, dt, min_ref=min_ref, max_ref=max_ref):\n",
    "    \"\"\"TODO: docstring.\"\"\"\n",
    "    # Define a reference trajectory in terms of spline coefficients\n",
    "    def reference(t):\n",
    "        r = jnp.array([spline(t, t_knots, c) for c in coefs])\n",
    "        r = jnp.clip(r, min_ref, max_ref)\n",
    "        return r\n",
    "    t, x, R_flatten, Omega, A, c = ensemble_sim(meta_params, pnorm_param, ensemble_params,\n",
    "                                reference, T, dt)\n",
    "    return t, x, R_flatten, Omega, A, c\n",
    "\n",
    "@partial(jax.jit, static_argnums=(5, 6))\n",
    "def loss(meta_params, pnorm_param, ensemble_params, t_knots, coefs, T, dt,\n",
    "            regularizer_l2, regularizer_ctrl, regularizer_error, regularizer_P):\n",
    "    \"\"\"TODO: docstring.\"\"\"\n",
    "    # Simulate on each model for each reference trajectory\n",
    "    t, x, R_flatten, Omega, A, c = simulate(meta_params, pnorm_param, ensemble_params, t_knots,\n",
    "                            coefs, T, dt)\n",
    "\n",
    "    # Sum final costs over reference trajectories and ensemble models\n",
    "    # Note `c` has shape (`num_refs`, `num_models`, `T // dt`, 3)\n",
    "    c_final = jnp.sum(c[:, :, -1, :], axis=(0, 1))\n",
    "\n",
    "    # Form a composite loss by weighting the different cost integrals,\n",
    "    # and normalizing by the number of models, number of reference\n",
    "    # trajectories, and time horizon\n",
    "    num_refs = c.shape[0]\n",
    "    num_models = c.shape[1]\n",
    "    normalizer = T * num_refs * num_models\n",
    "    tracking_loss, control_loss, estimation_loss = c_final\n",
    "    reg_P_penalty = jnp.linalg.norm(meta_params['gains']['P'])**2\n",
    "    l2_penalty = tree_normsq((meta_params['W'], meta_params['b']))\n",
    "    # regularization on P Frobenius norm shouldn't be normalized\n",
    "    loss = (tracking_loss\n",
    "            + regularizer_ctrl*control_loss\n",
    "            + regularizer_error*estimation_loss\n",
    "            + regularizer_l2*l2_penalty\n",
    "            ) / normalizer + regularizer_P * reg_P_penalty\n",
    "    \n",
    "\n",
    "    aux = {\n",
    "        # for each model in ensemble\n",
    "        'tracking_loss':   jnp.sum(c[:, :, -1, 0], axis=0) / num_refs,\n",
    "        'control_loss':    jnp.sum(c[:, :, -1, 1], axis=0) / num_refs,\n",
    "        'estimation_loss': jnp.sum(c[:, :, -1, 2], axis=0) / num_refs,\n",
    "        'l2_penalty':      l2_penalty,\n",
    "        'reg_P_penalty': reg_P_penalty,\n",
    "        'eigs_Λ':\n",
    "            jnp.diag(params_to_cholesky(meta_params['gains']['Λ']))**2,\n",
    "        'eigs_K':\n",
    "            jnp.diag(params_to_cholesky(meta_params['gains']['K']))**2,\n",
    "        'eigs_P':\n",
    "            jnp.diag(params_to_cholesky(meta_params['gains']['P']))**2,\n",
    "        'pnorm': pnorm_param['pnorm']\n",
    "    }\n",
    "    return loss, aux\n",
    "\n",
    "# Shuffle and split ensemble into training and validation sets\n",
    "train_frac = hparams['meta']['train_frac']\n",
    "num_train_models = int(train_frac * num_models)\n",
    "key, subkey = jax.random.split(key, 2)\n",
    "model_idx = jax.random.permutation(subkey, num_models)\n",
    "train_model_idx = model_idx[:num_train_models]\n",
    "valid_model_idx = model_idx[num_train_models:]\n",
    "train_ensemble = jax.tree_util.tree_map(lambda x: x[train_model_idx],\n",
    "                                        best_ensemble)\n",
    "valid_ensemble = jax.tree_util.tree_map(lambda x: x[valid_model_idx],\n",
    "                                        best_ensemble)\n",
    "\n",
    "# Split reference trajectories into training and validation sets\n",
    "num_train_refs = int(train_frac * num_refs)\n",
    "train_t_knots = jax.tree_util.tree_map(lambda a: a[:num_train_refs],\n",
    "                                        t_knots)\n",
    "train_coefs = jax.tree_util.tree_map(lambda a: a[:num_train_refs], coefs)\n",
    "valid_t_knots = jax.tree_util.tree_map(lambda a: a[num_train_refs:],\n",
    "                                        t_knots)\n",
    "valid_coefs = jax.tree_util.tree_map(lambda a: a[num_train_refs:], coefs)\n",
    "\n",
    "# Initialize gradient-based optimizer (ADAM)\n",
    "learning_rate = hparams['meta']['learning_rate']\n",
    "init_opt, update_opt, get_params = optimizers.adam(learning_rate)\n",
    "# Update meta_params and pnorm_param separately\n",
    "opt_meta = init_opt(meta_params)\n",
    "opt_pnorm = init_opt(pnorm_param)\n",
    "step_meta_idx = 0\n",
    "step_pnorm_idx = 0\n",
    "best_idx_meta = 0\n",
    "best_idx_pnorm = 0\n",
    "best_loss = jnp.inf\n",
    "best_meta_params = meta_params\n",
    "best_pnorm_param = pnorm_param\n",
    "\n",
    "@partial(jax.jit, static_argnums=(6, 7))\n",
    "def step_meta(idx, opt_state, pnorm_param, ensemble_params, t_knots, coefs, T, dt, regularizer_l2, regularizer_ctrl, regularizer_error, regularizer_P):\n",
    "    \"\"\"This function only updates the meta_params in an iteration\"\"\"\n",
    "    meta_params = get_params(opt_state)\n",
    "    grads, aux = jax.grad(loss, argnums=0, has_aux=True)(\n",
    "        meta_params, pnorm_param, ensemble_params, t_knots, coefs, T, dt,\n",
    "        regularizer_l2, regularizer_ctrl, regularizer_error, regularizer_P\n",
    "    )\n",
    "    opt_state = update_opt(idx, grads, opt_state)\n",
    "    return opt_state, aux, grads\n",
    "\n",
    "@partial(jax.jit, static_argnums=(6, 7))\n",
    "def step_pnorm(idx, meta_params, opt_state, ensemble_params, t_knots, coefs, T, dt, regularizer_l2, regularizer_ctrl, regularizer_error, regularizer_P):\n",
    "    \"\"\"This function only updates the meta_params in an iteration\"\"\"\n",
    "    pnorm_param = get_params(opt_state)\n",
    "    grads, aux = jax.grad(loss, argnums=1, has_aux=True)(\n",
    "        meta_params, pnorm_param, ensemble_params, t_knots, coefs, T, dt,\n",
    "        regularizer_l2, regularizer_ctrl, regularizer_error, regularizer_P\n",
    "    )\n",
    "    opt_state = update_opt(idx, grads, opt_state)\n",
    "    return opt_state, aux, grads\n",
    "\n",
    "# Pre-compile before training\n",
    "print('META-TRAINING: Pre-compiling ... ', end='', flush=True)\n",
    "dt = hparams['meta']['dt']\n",
    "T = hparams['meta']['T']\n",
    "regularizer_l2 = hparams['meta']['regularizer_l2']\n",
    "regularizer_ctrl = hparams['meta']['regularizer_ctrl']\n",
    "regularizer_error = hparams['meta']['regularizer_error']\n",
    "regularizer_P = hparams['meta']['regularizer_P']\n",
    "start = time.time()\n",
    "_ = step_meta(0, opt_meta, pnorm_param, train_ensemble, train_t_knots, train_coefs, T, dt, regularizer_l2, regularizer_ctrl, regularizer_error, regularizer_P)\n",
    "_ = step_pnorm(0, meta_params, opt_pnorm, train_ensemble, train_t_knots, train_coefs, T, dt, regularizer_l2, regularizer_ctrl, regularizer_error, regularizer_P)\n",
    "_ = loss(meta_params, pnorm_param, valid_ensemble, valid_t_knots, valid_coefs, T, dt,\n",
    "            0., 0., 0., 0.)\n",
    "end = time.time()\n",
    "print('done ({:.2f} s)! Now training ...'.format(\n",
    "        end - start))\n",
    "\n",
    "# Record pnorm and training loss history\n",
    "train_lossaux_history = []\n",
    "valid_loss_history = []\n",
    "pnorm_history = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Do gradient descent\n",
    "for i in tqdm(range(hparams['meta']['num_steps'])):\n",
    "    opt_meta, train_aux_meta, grads_meta = step_meta(\n",
    "        step_meta_idx, opt_meta, pnorm_param, train_ensemble, train_t_knots, train_coefs,\n",
    "        T, dt, regularizer_l2, regularizer_ctrl, regularizer_error, regularizer_P\n",
    "    )\n",
    "    # print(train_aux_meta)\n",
    "    new_meta_params = get_params(opt_meta)\n",
    "\n",
    "    # Update p-norm parameter\n",
    "    # The i+1 is to make sure not to update p-norm at step 0\n",
    "    if (i+1) % hparams['meta']['p_freq'] == 0:\n",
    "        opt_pnorm, train_aux_pnorm, grads_pnorm = step_pnorm(\n",
    "            step_pnorm_idx, new_meta_params, opt_pnorm, train_ensemble, train_t_knots, train_coefs,\n",
    "            T, dt, regularizer_l2, regularizer_ctrl, regularizer_error, regularizer_P\n",
    "        )\n",
    "        step_pnorm_idx += 1\n",
    "        # jdebug.print('{grad_pnorm}', grad_pnorm=grads_pnorm)\n",
    "        # jdebug.print('{meta_grad}', meta_grad=grads_meta)\n",
    "        print(\"Update p-norm to {:.2f} at step {:d}\".format(convert_qbar_p(get_params(opt_pnorm)['pnorm']), step_meta_idx))\n",
    "        pnorm_history.append(convert_qbar_p(get_params(opt_pnorm)['pnorm']))\n",
    "        train_lossaux_history.append(train_aux_pnorm)\n",
    "    else:\n",
    "        train_lossaux_history.append(train_aux_meta)\n",
    "\n",
    "    new_pnorm_param = get_params(opt_pnorm)\n",
    "        \n",
    "    valid_loss, valid_aux = loss(\n",
    "        new_meta_params, new_pnorm_param, valid_ensemble, valid_t_knots, valid_coefs,\n",
    "        T, dt, 0., 0., 0., 0.\n",
    "    )\n",
    "    train_loss, train_aux = loss(\n",
    "        new_meta_params, new_pnorm_param, train_ensemble, train_t_knots, train_coefs,\n",
    "        T, dt, regularizer_l2, regularizer_ctrl, regularizer_error, regularizer_P)\n",
    "    \n",
    "    valid_loss_history.append(valid_loss)\n",
    "\n",
    "    # Only update best_meta_params when the loss is decreasing\n",
    "    if valid_loss < best_loss:\n",
    "        best_meta_params = new_meta_params\n",
    "        best_pnorm_param = new_pnorm_param\n",
    "        best_loss = valid_loss\n",
    "        best_idx_meta = step_meta_idx\n",
    "        best_idx_pnorm = step_pnorm_idx\n",
    "    step_meta_idx += 1\n",
    "\n",
    "# Save hyperparameters, ensemble, model, and controller\n",
    "output_name = \"seed={:d}_M={:d}_E={:d}_pinit={:.2f}_pfreq={:.0f}_regP={:.4f}\".format(hparams['seed'], num_models, args.meta_epochs, args.pnorm_init, hparams['meta']['p_freq'], hparams['meta']['regularizer_P'])\n",
    "results = {\n",
    "    'best_step_meta': best_idx_meta,\n",
    "    'best_step_pnorm': best_idx_pnorm,\n",
    "    'hparams': hparams,\n",
    "    'ensemble': best_ensemble,\n",
    "    'model': {\n",
    "        'W': best_meta_params['W'],\n",
    "        'b': best_meta_params['b'],\n",
    "    },\n",
    "    'controller': best_meta_params['gains'],\n",
    "    'pnorm': convert_qbar_p(best_pnorm_param['pnorm']),\n",
    "    'regP': hparams['meta']['regularizer_P'],\n",
    "    'train_lossaux_history': train_lossaux_history,\n",
    "    'valid_loss_history': valid_loss_history,\n",
    "    'pnorm_history': pnorm_history\n",
    "}\n",
    "output_dir = os.path.join('train_results', args.output_dir)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "output_path = os.path.join(output_dir, output_name + '.pkl')\n",
    "with open(output_path, 'wb') as file:\n",
    "    pickle.dump(results, file)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Meta-training completes with p-norm chosen as {:.2f}\".format(results['pnorm']))\n",
    "print('done ({:.2f} s)! Best step index for meta params: {}'.format(end - start, best_idx_meta))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
